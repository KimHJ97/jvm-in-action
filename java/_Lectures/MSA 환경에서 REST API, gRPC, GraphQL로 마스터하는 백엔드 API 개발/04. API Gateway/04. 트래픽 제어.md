# 트래픽 제어

## 1. 트래픽 제어의 중요성

트래픽 제어란 클라이언트로부터 오는 요청을 관리, 조절, 최적화하는 과정을 의미한다.  
서버 오버로드 방지, 서비스의 안정적인 운영, 사용자 요청에 대한 효율적인 처리 등이 가능하다.  
 - 부하 관리: 서버가 처리할 수 있는 한도를 초과하지 않도록 트래픽을 제한하거나 분산하여 서버의 부하를 관리합니다.
 - 성능 최적화: 네트워크 및 시스템의 성능을 향상시키기 위해 트래픽을 조절하고 최적화합니다.
 - 보안 강화: DDoS(분산 서비스 거부 공격)와 같은 공격으로부터 시스템을 보호하기 위해 트래픽을 제한하거나 필터링합니다.

<br/>

### 트래픽 제어 방법

#### Rate Limiting

Rate Limiting은 특정 시간 동안 허용되는 요청의 수를 제한하여 과도한 요청을 방지하는 메커니즘입니다. 주로 API Gateway나 서버에서 API 요청을 관리하거나, 사용자 인터페이스에서의 요청 처리 등에서 사용됩니다.  
 - 예를 들어, 1분당 최대 100개의 API 요청을 허용하도록 설정할 수 있습니다.
 - 클라이언트가 정해진 제한을 초과하는 요청을 시도하면, HTTP 상태 코드로 에러를 반환하거나 요청을 거부할 수 있습니다.
 - 서비스의 과부하를 방지하고, 서버의 안정성을 유지하는 데 도움을 줍니다.

<br/>

#### Throttling

Throttling은 서버의 부하가 증가할 때 요청 처리 속도를 자동으로 조절하여 서버가 과부하 상태에 이르는 것을 방지하는 방법입니다.  
 - 동적으로 서버의 현재 상태를 모니터링하고, 부하가 증가하면 요청을 처리하는 속도를 낮춥니다.
 - 예를 들어, 일정 시간 동안의 평균 부하가 일정 값 이상이면 요청을 일부 거부하거나 처리 속도를 제한할 수 있습니다.
 - 서버의 성능을 유지하고 사용자 경험을 향상시키는 데 도움을 줍니다.

<br/>

#### Load Balancing

Load Balancing은 들어오는 트래픽을 여러 서버에 분산시켜 처리 능력을 극대화하고, 단일 장애 지점을 제거하는 기술입니다.  
 - 트래픽 분산, 알고리즘 적용, 상태 확인, 유연한 확장성
 - 여러 서버에 트래픽을 분산하여 각 서버가 균형 있게 작업을 처리할 수 있습니다.
 - 서버의 부하를 골고루 분배하여 전체 시스템의 성능을 최적화하고, 단일 서버의 고장 시 서비스 중단을 방지합니다.
 - 클라우드 환경에서는 자동으로 서버 인스턴스를 관리하고 트래픽을 분산하는 로드 밸런서 서비스를 제공합니다.

<br/>

#### Caching

Caching은 자주 요청되는 데이터를 임시로 저장하여 빠르게 응답할 수 있게 하는 메커니즘입니다.  
 - 초기 요청 처리, 캐시 저장, 캐시 히트와 미스
    - 동일한 요청에 대해 빠르게 응답 제공
    - 서버의 처리 부하를 줄이고 사용자에게 더 나은 경험 제공
 - 빈번히 접근되는 데이터나 API 응답을 메모리나 디스크에 저장하여 다음 요청 시에 재사용할 수 있습니다.
 - 데이터베이스나 외부 서비스로부터 데이터를 가져오는 데 걸리는 시간을 절약하고, 전체 시스템의 응답 시간을 줄입니다.
 - 캐싱 정책을 설정하여 데이터의 유효 기간을 관리하고, 적절한 경우 캐시를 갱신하거나 삭제할 수 있습니다.


## 2. 트래픽 제어 구현 사례

### Late Limiting

Spring 프레임워크에서 Rate Limiting을 구현하는 방법은 여러 가지가 있지만, 주로 인터셉터(Interceptor)나 필터(Filter)를 사용하여 구현하는 경우가 많습니다. 이를 통해 요청의 IP 주소나 사용자 ID를 기반으로 요청 수를 카운팅하고, 설정된 한계를 초과하는 경우 요청을 거부할 수 있습니다.  
 - Bucket4j, Spring Cloud Gateway

#### Rate Limiting 알고리즘 종류

 - 고정 윈도우 알고리즘: 가장 단순한 Rate Limit 알고리즘
 - 슬라이딩 로그 알고리즘: 윈도우 내에 있는 로그의 수를 계산하여 요청이 제한을 초과하는 지 판단
 - 슬라이딩 윈도우 카운터 알고리즘: 고정 윈도우와 슬라이딩 로그의 장점 결합
 - 토큰 버킷 알고리즘: 일정한 속도로 토큰을 버킷에 추가, 버킷이 가득찬 경우 API 요청 버림
 - 릭키 버킷 알고리즘: 토큰 버킷과 비슷하지만, 고정 큐로 FIFO로 구현

<br/>

#### Rate Limiting - Bucket4j

```java
public class RateLimitInterceptor implements HandlerInterceptor {

    private final Map<String, Bucket> buckets = new ConcurrentHashMap<>();

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        String ip = request.getRemoteAddr();
        Bucket bucket = buckets.computeIfAbsent(ip, this::createBucket);

        if (bucket.tryConsume(1)) { // 요청이 성공적으로 처리됨
            return true;
        } else { // 레이트 리밋에 도달했을 경우, HTTP 429 오류를 반환
            response.setContentType("text/plain");
            response.setStatus(HttpServletResponse.SC_TOO_MANY_REQUESTS);
            response.getWriter().append("Too many requests");
            return false;
        }
    }

    private Bucket createBucket(String ip) {
        // 시간당 100개의 요청을 허용하는 레이트 리밋 정책
        Bandwidth limit = Bandwidth.classic(100, Refill.greedy(100, Duration.ofHours(1)));
        return Bucket4j.builder().addLimit(limit).build();
    }
}
```
<br/>

#### Rate Limiting - Spring Cloud Gateway

 - `application.yml`
```yml
spring:
  cloud:
    gateway:
      routes:
       - id: example-route
         uri: http://example.com
         prediccates:
          - Path=/example/**
         filters:
          - name: RequestRateLimiter
            args:
              redis-rate-limiter.replenishRate: 5
              redis-rate-limiter.burstCapacity: 10
              key-resolver: "#{@ipKeyResolver}"

  redis:
    host: localhost
    port: 6379
```
<br/>

```java
@Configuration
public class RateLimiterConfig {
    @Bean
    KeyResolver ipKeyResolver() {
        return exchange -> Mono.just(exchange.getRequest().getRemoteAddress.getHostName());
    }
}
```
<br/>

### Throttling

Throttling은 서버 부하를 조절하여 과부하를 방지하고, 시스템의 안정성을 보장한다.  
Spring에서 Throttling은 주로 서비스 또는 컨트롤러 레벨에서 구현되며, 요청의 처리량을 조절한다.  
 - Resilience4j
```java
@Service
public class RateLimitedService {

    @RateLimiter(name = "backendA")
    public String rateLimitedMethod() {
        return "";
    }
}
```
<br/>

 - `application.yml`
```yml
resilience4j.ratelimiter:
  instances:
    backendA:
      limitForPeriod: 10
      limitRefreshPeriod: 1s
      timeoutDuration: 0ms
```
<br/>

### Load Balancing

로드 밸런싱은 들어오는 트래픽을 여러 서버에 분산시켜 전체 시스템의 처리 능력을 향상시킨다.  
Spring Cloud 에서는 서비스 레지스트리(Eureka)와 함께 Ribbon이나 Spring Cloud LoadBlanacer를 사용하여 클라이언트 측 로드 밸런싱을 구현한다.  
 - Spring Cloud LoadBalancer

```java
@Service
public class ExampleService {
    @Autowired
    private RestTemplate restTemplate;

    public String callService(String serviceName) {
        String url = "http://" + serviceName + "/some-endpoint";
        return restTemplate.getForObject(url, String.class);
    }
}

@Configuration
public class AppConfig {
    @Bean
    @LoadBlanced
    public RestTemplate loadBalancedRestTemplate() {
        return new RestTemplate();
    }
}
```
